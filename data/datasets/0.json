{
    "id": 0,
    "name": "Scratch Dataset",
    "records": [
        {
            "id": 0,
            "input_data": "b'Generative artificial intelligence (also generative AI or GenAI[1]) is artificial intelligence capable of generating text, images, or other media, using generative models.[2][3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.[5][6]\\n\\nIn the early 2020s, advances in transformer-based deep neural networks enabled a number of generative AI systems notable for accepting natural language prompts as input. These include large language model chatbots such as ChatGPT, Bing Chat, Bard, and LLaMA, and text-to-image artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.[7][8][9]\\n\\nGenerative AI has uses across a wide range of industries, including art, writing, software development, product design, healthcare, finance, gaming, marketing, and fashion.[10][11][12] Investment in generative AI surged during the early 2020s, with large companies such as Microsoft, Google, and Baidu as well as numerous smaller firms developing generative AI models.[2][13][14] However, there are also concerns about the potential misuse of generative AI, including cybercrime or creating fake news or deepfakes which can be used to deceive or manipulate people.[15]'",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 1,
            "input_data": "b'Generative artificial intelligence (also generative AI or GenAI[1]) is artificial intelligence capable of generating text, images, or other media, using generative models.[2][3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.[5][6]\\n\\nIn the early 2020s, advances in transformer-based deep neural networks enabled a number of generative AI systems notable for accepting natural language prompts as input. These include large language model chatbots such as ChatGPT, Bing Chat, Bard, and LLaMA, and text-to-image artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.[7][8][9]\\n\\nGenerative AI has uses across a wide range of industries, including art, writing, software development, product design, healthcare, finance, gaming, marketing, and fashion.[10][11][12] Investment in generative AI surged during the early 2020s, with large companies such as Microsoft, Google, and Baidu as well as numerous smaller firms developing generative AI models.[2][13][14] However, there are also concerns about the potential misuse of generative AI, including cybercrime or creating fake news or deepfakes which can be used to deceive or manipulate people.[15]'",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 2,
            "input_data": "b'Generative artificial intelligence (also generative AI or GenAI[1]) is artificial intelligence capable of generating text, images, or other media, using generative models.[2][3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.[5][6]\\n\\nIn the early 2020s, advances in transformer-based deep neural networks enabled a number of generative AI systems notable for accepting natural language prompts as input. These include large language model chatbots such as ChatGPT, Bing Chat, Bard, and LLaMA, and text-to-image artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.[7][8][9]\\n\\nGenerative AI has uses across a wide range of industries, including art, writing, software development, product design, healthcare, finance, gaming, marketing, and fashion.[10][11][12] Investment in generative AI surged during the early 2020s, with large companies such as Microsoft, Google, and Baidu as well as numerous smaller firms developing generative AI models.[2][13][14] However, there are also concerns about the potential misuse of generative AI, including cybercrime or creating fake news or deepfakes which can be used to deceive or manipulate people.[15]'",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 3,
            "input_data": "b\"Everyone Hates Model Documentation. Verta Is Changing That.\\nJuly 24, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nAndy Butkovic\\n\\nBlog-AIAD-01\\n\\nIt\\xe2\\x80\\x99s no secret that documentation is, well, boring. Writing documentation is the least interesting part of the day for creators like data scientists and software engineers. \\n\\nML model documentation is particularly tedious because you have to document not only the model object itself, but also how the model came to be, its performance and limitations, and explainability and fairness metrics. Little wonder that data scientists report spending 40+ hours to document a single model, according to a recent study.\\n\\nAt the same time, we all know that model documentation is increasingly essential to prevent knowledge loss when data scientists leave the company, ensure that the users of a model have the information they need to use it properly, and comply with increasing AI regulations or prevent massive fines.\\n\\nAnd so, at Verta, we want to help model builders write documentation without distracting from creative work!\\n\\nSeeing Is Believing \\nWatch this demo to learn how easy it is to use Verta's AI assistant to quickly create complete and accurate model documentation   \\n\\nView the Demo\\n     \\nLeveraging AI to Document AI\\nLLMs are well known to be incredibly effective at writing and summarizing text and code. So we decided to leverage AI to document AI.  \\n\\nToday we are launching into public preview Verta's brand new AI Assisted Documentation (AIAD) capabilities. AIAD is a \\xe2\\x80\\x9cdocumentation copilot\\xe2\\x80\\x9d that handles the heavy lifting of collecting, collating and formatting information required to document a model. You can then review and amend the documentation produced by your AI assistant to ensure that it meets required standards and accurately incorporates all the necessary data.\\n\\nTo get started, just upload the model into the Verta Model Catalog and let your AI sidekick make documentation a breeze.\\n\\n\\nVerta\\xe2\\x80\\x99s AIAD capabilities combine three simple ideas:\\nProviding templates for model documentation following best practices (e.g., model cards, system cards)\\nProviding LLM-enabled writing assistance and suggestions based on the model\\nAutomatically generating documentation using information contained in the model itself (e.g., APIs)\\nTo optimize the LLM outputs for model documentation, we trained the model on a library of well-known model cards to replicate the tone, style, and level of detail. We also spent many cycles optimizing and validating the results for a variety of types of models to minimize hallucinations. \\n\\nWe've seen different attempts to systematize the requirements for model documentation, such as Google's model cards. But these efforts haven\\xe2\\x80\\x99t gained traction because data scientists simply don\\xe2\\x80\\x99t have the time or writing support to complete them. In fact, a recent CHI paper on documentation found that model cards from sources like Hugging Face and GitHub often were vague, incomplete, and failed to address ethical dimensions of models. Verta's AI-Assisted Documentation turns model cards from great-in-theory to great-in-practice.\\n\\nAccelerate Documentation 10x Starting Now\\nOur initial tests suggest that Verta\\xe2\\x80\\x99s AIAD capabilities can accelerate documentation creation by up to 10X, but we think we can push it even further!\\n\\nUpload your models to see how AIAD can help you write model documentation.\\n\\nHappy writing, building!\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 4,
            "input_data": "b\"Everyone Hates Model Documentation. Verta Is Changing That.\\nJuly 24, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nAndy Butkovic\\n\\nBlog-AIAD-01\\n\\nIt\\xe2\\x80\\x99s no secret that documentation is, well, boring. Writing documentation is the least interesting part of the day for creators like data scientists and software engineers. \\n\\nML model documentation is particularly tedious because you have to document not only the model object itself, but also how the model came to be, its performance and limitations, and explainability and fairness metrics. Little wonder that data scientists report spending 40+ hours to document a single model, according to a recent study.\\n\\nAt the same time, we all know that model documentation is increasingly essential to prevent knowledge loss when data scientists leave the company, ensure that the users of a model have the information they need to use it properly, and comply with increasing AI regulations or prevent massive fines.\\n\\nAnd so, at Verta, we want to help model builders write documentation without distracting from creative work!\\n\\nSeeing Is Believing \\nWatch this demo to learn how easy it is to use Verta's AI assistant to quickly create complete and accurate model documentation   \\n\\nView the Demo\\n     \\nLeveraging AI to Document AI\\nLLMs are well known to be incredibly effective at writing and summarizing text and code. So we decided to leverage AI to document AI.  \\n\\nToday we are launching into public preview Verta's brand new AI Assisted Documentation (AIAD) capabilities. AIAD is a \\xe2\\x80\\x9cdocumentation copilot\\xe2\\x80\\x9d that handles the heavy lifting of collecting, collating and formatting information required to document a model. You can then review and amend the documentation produced by your AI assistant to ensure that it meets required standards and accurately incorporates all the necessary data.\\n\\nTo get started, just upload the model into the Verta Model Catalog and let your AI sidekick make documentation a breeze.\\n\\n\\nVerta\\xe2\\x80\\x99s AIAD capabilities combine three simple ideas:\\nProviding templates for model documentation following best practices (e.g., model cards, system cards)\\nProviding LLM-enabled writing assistance and suggestions based on the model\\nAutomatically generating documentation using information contained in the model itself (e.g., APIs)\\nTo optimize the LLM outputs for model documentation, we trained the model on a library of well-known model cards to replicate the tone, style, and level of detail. We also spent many cycles optimizing and validating the results for a variety of types of models to minimize hallucinations. \\n\\nWe've seen different attempts to systematize the requirements for model documentation, such as Google's model cards. But these efforts haven\\xe2\\x80\\x99t gained traction because data scientists simply don\\xe2\\x80\\x99t have the time or writing support to complete them. In fact, a recent CHI paper on documentation found that model cards from sources like Hugging Face and GitHub often were vague, incomplete, and failed to address ethical dimensions of models. Verta's AI-Assisted Documentation turns model cards from great-in-theory to great-in-practice.\\n\\nAccelerate Documentation 10x Starting Now\\nOur initial tests suggest that Verta\\xe2\\x80\\x99s AIAD capabilities can accelerate documentation creation by up to 10X, but we think we can push it even further!\\n\\nUpload your models to see how AIAD can help you write model documentation.\\n\\nHappy writing, building!\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 5,
            "input_data": "b\"Everyone Hates Model Documentation. Verta Is Changing That.\\nJuly 24, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nAndy Butkovic\\n\\nBlog-AIAD-01\\n\\nIt\\xe2\\x80\\x99s no secret that documentation is, well, boring. Writing documentation is the least interesting part of the day for creators like data scientists and software engineers. \\n\\nML model documentation is particularly tedious because you have to document not only the model object itself, but also how the model came to be, its performance and limitations, and explainability and fairness metrics. Little wonder that data scientists report spending 40+ hours to document a single model, according to a recent study.\\n\\nAt the same time, we all know that model documentation is increasingly essential to prevent knowledge loss when data scientists leave the company, ensure that the users of a model have the information they need to use it properly, and comply with increasing AI regulations or prevent massive fines.\\n\\nAnd so, at Verta, we want to help model builders write documentation without distracting from creative work!\\n\\nSeeing Is Believing \\nWatch this demo to learn how easy it is to use Verta's AI assistant to quickly create complete and accurate model documentation   \\n\\nView the Demo\\n     \\nLeveraging AI to Document AI\\nLLMs are well known to be incredibly effective at writing and summarizing text and code. So we decided to leverage AI to document AI.  \\n\\nToday we are launching into public preview Verta's brand new AI Assisted Documentation (AIAD) capabilities. AIAD is a \\xe2\\x80\\x9cdocumentation copilot\\xe2\\x80\\x9d that handles the heavy lifting of collecting, collating and formatting information required to document a model. You can then review and amend the documentation produced by your AI assistant to ensure that it meets required standards and accurately incorporates all the necessary data.\\n\\nTo get started, just upload the model into the Verta Model Catalog and let your AI sidekick make documentation a breeze.\\n\\n\\nVerta\\xe2\\x80\\x99s AIAD capabilities combine three simple ideas:\\nProviding templates for model documentation following best practices (e.g., model cards, system cards)\\nProviding LLM-enabled writing assistance and suggestions based on the model\\nAutomatically generating documentation using information contained in the model itself (e.g., APIs)\\nTo optimize the LLM outputs for model documentation, we trained the model on a library of well-known model cards to replicate the tone, style, and level of detail. We also spent many cycles optimizing and validating the results for a variety of types of models to minimize hallucinations. \\n\\nWe've seen different attempts to systematize the requirements for model documentation, such as Google's model cards. But these efforts haven\\xe2\\x80\\x99t gained traction because data scientists simply don\\xe2\\x80\\x99t have the time or writing support to complete them. In fact, a recent CHI paper on documentation found that model cards from sources like Hugging Face and GitHub often were vague, incomplete, and failed to address ethical dimensions of models. Verta's AI-Assisted Documentation turns model cards from great-in-theory to great-in-practice.\\n\\nAccelerate Documentation 10x Starting Now\\nOur initial tests suggest that Verta\\xe2\\x80\\x99s AIAD capabilities can accelerate documentation creation by up to 10X, but we think we can push it even further!\\n\\nUpload your models to see how AIAD can help you write model documentation.\\n\\nHappy writing, building!\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 6,
            "input_data": "b\"Everyone Hates Model Documentation. Verta Is Changing That.\\nJuly 24, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nAndy Butkovic\\n\\nBlog-AIAD-01\\n\\nIt\\xe2\\x80\\x99s no secret that documentation is, well, boring. Writing documentation is the least interesting part of the day for creators like data scientists and software engineers. \\n\\nML model documentation is particularly tedious because you have to document not only the model object itself, but also how the model came to be, its performance and limitations, and explainability and fairness metrics. Little wonder that data scientists report spending 40+ hours to document a single model, according to a recent study.\\n\\nAt the same time, we all know that model documentation is increasingly essential to prevent knowledge loss when data scientists leave the company, ensure that the users of a model have the information they need to use it properly, and comply with increasing AI regulations or prevent massive fines.\\n\\nAnd so, at Verta, we want to help model builders write documentation without distracting from creative work!\\n\\nSeeing Is Believing \\nWatch this demo to learn how easy it is to use Verta's AI assistant to quickly create complete and accurate model documentation   \\n\\nView the Demo\\n     \\nLeveraging AI to Document AI\\nLLMs are well known to be incredibly effective at writing and summarizing text and code. So we decided to leverage AI to document AI.  \\n\\nToday we are launching into public preview Verta's brand new AI Assisted Documentation (AIAD) capabilities. AIAD is a \\xe2\\x80\\x9cdocumentation copilot\\xe2\\x80\\x9d that handles the heavy lifting of collecting, collating and formatting information required to document a model. You can then review and amend the documentation produced by your AI assistant to ensure that it meets required standards and accurately incorporates all the necessary data.\\n\\nTo get started, just upload the model into the Verta Model Catalog and let your AI sidekick make documentation a breeze.\\n\\n\\nVerta\\xe2\\x80\\x99s AIAD capabilities combine three simple ideas:\\nProviding templates for model documentation following best practices (e.g., model cards, system cards)\\nProviding LLM-enabled writing assistance and suggestions based on the model\\nAutomatically generating documentation using information contained in the model itself (e.g., APIs)\\nTo optimize the LLM outputs for model documentation, we trained the model on a library of well-known model cards to replicate the tone, style, and level of detail. We also spent many cycles optimizing and validating the results for a variety of types of models to minimize hallucinations. \\n\\nWe've seen different attempts to systematize the requirements for model documentation, such as Google's model cards. But these efforts haven\\xe2\\x80\\x99t gained traction because data scientists simply don\\xe2\\x80\\x99t have the time or writing support to complete them. In fact, a recent CHI paper on documentation found that model cards from sources like Hugging Face and GitHub often were vague, incomplete, and failed to address ethical dimensions of models. Verta's AI-Assisted Documentation turns model cards from great-in-theory to great-in-practice.\\n\\nAccelerate Documentation 10x Starting Now\\nOur initial tests suggest that Verta\\xe2\\x80\\x99s AIAD capabilities can accelerate documentation creation by up to 10X, but we think we can push it even further!\\n\\nUpload your models to see how AIAD can help you write model documentation.\\n\\nHappy writing, building!\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 7,
            "input_data": "b\"Everyone Hates Model Documentation. Verta Is Changing That.\\nJuly 24, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nAndy Butkovic\\n\\nBlog-AIAD-01\\n\\nIt\\xe2\\x80\\x99s no secret that documentation is, well, boring. Writing documentation is the least interesting part of the day for creators like data scientists and software engineers. \\n\\nML model documentation is particularly tedious because you have to document not only the model object itself, but also how the model came to be, its performance and limitations, and explainability and fairness metrics. Little wonder that data scientists report spending 40+ hours to document a single model, according to a recent study.\\n\\nAt the same time, we all know that model documentation is increasingly essential to prevent knowledge loss when data scientists leave the company, ensure that the users of a model have the information they need to use it properly, and comply with increasing AI regulations or prevent massive fines.\\n\\nAnd so, at Verta, we want to help model builders write documentation without distracting from creative work!\\n\\nSeeing Is Believing \\nWatch this demo to learn how easy it is to use Verta's AI assistant to quickly create complete and accurate model documentation   \\n\\nView the Demo\\n     \\nLeveraging AI to Document AI\\nLLMs are well known to be incredibly effective at writing and summarizing text and code. So we decided to leverage AI to document AI.  \\n\\nToday we are launching into public preview Verta's brand new AI Assisted Documentation (AIAD) capabilities. AIAD is a \\xe2\\x80\\x9cdocumentation copilot\\xe2\\x80\\x9d that handles the heavy lifting of collecting, collating and formatting information required to document a model. You can then review and amend the documentation produced by your AI assistant to ensure that it meets required standards and accurately incorporates all the necessary data.\\n\\nTo get started, just upload the model into the Verta Model Catalog and let your AI sidekick make documentation a breeze.\\n\\n\\nVerta\\xe2\\x80\\x99s AIAD capabilities combine three simple ideas:\\nProviding templates for model documentation following best practices (e.g., model cards, system cards)\\nProviding LLM-enabled writing assistance and suggestions based on the model\\nAutomatically generating documentation using information contained in the model itself (e.g., APIs)\\nTo optimize the LLM outputs for model documentation, we trained the model on a library of well-known model cards to replicate the tone, style, and level of detail. We also spent many cycles optimizing and validating the results for a variety of types of models to minimize hallucinations. \\n\\nWe've seen different attempts to systematize the requirements for model documentation, such as Google's model cards. But these efforts haven\\xe2\\x80\\x99t gained traction because data scientists simply don\\xe2\\x80\\x99t have the time or writing support to complete them. In fact, a recent CHI paper on documentation found that model cards from sources like Hugging Face and GitHub often were vague, incomplete, and failed to address ethical dimensions of models. Verta's AI-Assisted Documentation turns model cards from great-in-theory to great-in-practice.\\n\\nAccelerate Documentation 10x Starting Now\\nOur initial tests suggest that Verta\\xe2\\x80\\x99s AIAD capabilities can accelerate documentation creation by up to 10X, but we think we can push it even further!\\n\\nUpload your models to see how AIAD can help you write model documentation.\\n\\nHappy writing, building!\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 8,
            "input_data": "b\"Everyone Hates Model Documentation. Verta Is Changing That.\\nJuly 24, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nAndy Butkovic\\n\\nBlog-AIAD-01\\n\\nIt\\xe2\\x80\\x99s no secret that documentation is, well, boring. Writing documentation is the least interesting part of the day for creators like data scientists and software engineers. \\n\\nML model documentation is particularly tedious because you have to document not only the model object itself, but also how the model came to be, its performance and limitations, and explainability and fairness metrics. Little wonder that data scientists report spending 40+ hours to document a single model, according to a recent study.\\n\\nAt the same time, we all know that model documentation is increasingly essential to prevent knowledge loss when data scientists leave the company, ensure that the users of a model have the information they need to use it properly, and comply with increasing AI regulations or prevent massive fines.\\n\\nAnd so, at Verta, we want to help model builders write documentation without distracting from creative work!\\n\\nSeeing Is Believing \\nWatch this demo to learn how easy it is to use Verta's AI assistant to quickly create complete and accurate model documentation   \\n\\nView the Demo\\n     \\nLeveraging AI to Document AI\\nLLMs are well known to be incredibly effective at writing and summarizing text and code. So we decided to leverage AI to document AI.  \\n\\nToday we are launching into public preview Verta's brand new AI Assisted Documentation (AIAD) capabilities. AIAD is a \\xe2\\x80\\x9cdocumentation copilot\\xe2\\x80\\x9d that handles the heavy lifting of collecting, collating and formatting information required to document a model. You can then review and amend the documentation produced by your AI assistant to ensure that it meets required standards and accurately incorporates all the necessary data.\\n\\nTo get started, just upload the model into the Verta Model Catalog and let your AI sidekick make documentation a breeze.\\n\\n\\nVerta\\xe2\\x80\\x99s AIAD capabilities combine three simple ideas:\\nProviding templates for model documentation following best practices (e.g., model cards, system cards)\\nProviding LLM-enabled writing assistance and suggestions based on the model\\nAutomatically generating documentation using information contained in the model itself (e.g., APIs)\\nTo optimize the LLM outputs for model documentation, we trained the model on a library of well-known model cards to replicate the tone, style, and level of detail. We also spent many cycles optimizing and validating the results for a variety of types of models to minimize hallucinations. \\n\\nWe've seen different attempts to systematize the requirements for model documentation, such as Google's model cards. But these efforts haven\\xe2\\x80\\x99t gained traction because data scientists simply don\\xe2\\x80\\x99t have the time or writing support to complete them. In fact, a recent CHI paper on documentation found that model cards from sources like Hugging Face and GitHub often were vague, incomplete, and failed to address ethical dimensions of models. Verta's AI-Assisted Documentation turns model cards from great-in-theory to great-in-practice.\\n\\nAccelerate Documentation 10x Starting Now\\nOur initial tests suggest that Verta\\xe2\\x80\\x99s AIAD capabilities can accelerate documentation creation by up to 10X, but we think we can push it even further!\\n\\nUpload your models to see how AIAD can help you write model documentation.\\n\\nHappy writing, building!\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 9,
            "input_data": "b\"Everyone Hates Model Documentation. Verta Is Changing That.\\nJuly 24, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nAndy Butkovic\\n\\nBlog-AIAD-01\\n\\nIt\\xe2\\x80\\x99s no secret that documentation is, well, boring. Writing documentation is the least interesting part of the day for creators like data scientists and software engineers. \\n\\nML model documentation is particularly tedious because you have to document not only the model object itself, but also how the model came to be, its performance and limitations, and explainability and fairness metrics. Little wonder that data scientists report spending 40+ hours to document a single model, according to a recent study.\\n\\nAt the same time, we all know that model documentation is increasingly essential to prevent knowledge loss when data scientists leave the company, ensure that the users of a model have the information they need to use it properly, and comply with increasing AI regulations or prevent massive fines.\\n\\nAnd so, at Verta, we want to help model builders write documentation without distracting from creative work!\\n\\nSeeing Is Believing \\nWatch this demo to learn how easy it is to use Verta's AI assistant to quickly create complete and accurate model documentation   \\n\\nView the Demo\\n     \\nLeveraging AI to Document AI\\nLLMs are well known to be incredibly effective at writing and summarizing text and code. So we decided to leverage AI to document AI.  \\n\\nToday we are launching into public preview Verta's brand new AI Assisted Documentation (AIAD) capabilities. AIAD is a \\xe2\\x80\\x9cdocumentation copilot\\xe2\\x80\\x9d that handles the heavy lifting of collecting, collating and formatting information required to document a model. You can then review and amend the documentation produced by your AI assistant to ensure that it meets required standards and accurately incorporates all the necessary data.\\n\\nTo get started, just upload the model into the Verta Model Catalog and let your AI sidekick make documentation a breeze.\\n\\n\\nVerta\\xe2\\x80\\x99s AIAD capabilities combine three simple ideas:\\nProviding templates for model documentation following best practices (e.g., model cards, system cards)\\nProviding LLM-enabled writing assistance and suggestions based on the model\\nAutomatically generating documentation using information contained in the model itself (e.g., APIs)\\nTo optimize the LLM outputs for model documentation, we trained the model on a library of well-known model cards to replicate the tone, style, and level of detail. We also spent many cycles optimizing and validating the results for a variety of types of models to minimize hallucinations. \\n\\nWe've seen different attempts to systematize the requirements for model documentation, such as Google's model cards. But these efforts haven\\xe2\\x80\\x99t gained traction because data scientists simply don\\xe2\\x80\\x99t have the time or writing support to complete them. In fact, a recent CHI paper on documentation found that model cards from sources like Hugging Face and GitHub often were vague, incomplete, and failed to address ethical dimensions of models. Verta's AI-Assisted Documentation turns model cards from great-in-theory to great-in-practice.\\n\\nAccelerate Documentation 10x Starting Now\\nOur initial tests suggest that Verta\\xe2\\x80\\x99s AIAD capabilities can accelerate documentation creation by up to 10X, but we think we can push it even further!\\n\\nUpload your models to see how AIAD can help you write model documentation.\\n\\nHappy writing, building!\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 10,
            "input_data": "b\"Everyone Hates Model Documentation. Verta Is Changing That.\\nJuly 24, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nAndy Butkovic\\n\\nBlog-AIAD-01\\n\\nIt\\xe2\\x80\\x99s no secret that documentation is, well, boring. Writing documentation is the least interesting part of the day for creators like data scientists and software engineers. \\n\\nML model documentation is particularly tedious because you have to document not only the model object itself, but also how the model came to be, its performance and limitations, and explainability and fairness metrics. Little wonder that data scientists report spending 40+ hours to document a single model, according to a recent study.\\n\\nAt the same time, we all know that model documentation is increasingly essential to prevent knowledge loss when data scientists leave the company, ensure that the users of a model have the information they need to use it properly, and comply with increasing AI regulations or prevent massive fines.\\n\\nAnd so, at Verta, we want to help model builders write documentation without distracting from creative work!\\n\\nSeeing Is Believing \\nWatch this demo to learn how easy it is to use Verta's AI assistant to quickly create complete and accurate model documentation   \\n\\nView the Demo\\n     \\nLeveraging AI to Document AI\\nLLMs are well known to be incredibly effective at writing and summarizing text and code. So we decided to leverage AI to document AI.  \\n\\nToday we are launching into public preview Verta's brand new AI Assisted Documentation (AIAD) capabilities. AIAD is a \\xe2\\x80\\x9cdocumentation copilot\\xe2\\x80\\x9d that handles the heavy lifting of collecting, collating and formatting information required to document a model. You can then review and amend the documentation produced by your AI assistant to ensure that it meets required standards and accurately incorporates all the necessary data.\\n\\nTo get started, just upload the model into the Verta Model Catalog and let your AI sidekick make documentation a breeze.\\n\\n\\nVerta\\xe2\\x80\\x99s AIAD capabilities combine three simple ideas:\\nProviding templates for model documentation following best practices (e.g., model cards, system cards)\\nProviding LLM-enabled writing assistance and suggestions based on the model\\nAutomatically generating documentation using information contained in the model itself (e.g., APIs)\\nTo optimize the LLM outputs for model documentation, we trained the model on a library of well-known model cards to replicate the tone, style, and level of detail. We also spent many cycles optimizing and validating the results for a variety of types of models to minimize hallucinations. \\n\\nWe've seen different attempts to systematize the requirements for model documentation, such as Google's model cards. But these efforts haven\\xe2\\x80\\x99t gained traction because data scientists simply don\\xe2\\x80\\x99t have the time or writing support to complete them. In fact, a recent CHI paper on documentation found that model cards from sources like Hugging Face and GitHub often were vague, incomplete, and failed to address ethical dimensions of models. Verta's AI-Assisted Documentation turns model cards from great-in-theory to great-in-practice.\\n\\nAccelerate Documentation 10x Starting Now\\nOur initial tests suggest that Verta\\xe2\\x80\\x99s AIAD capabilities can accelerate documentation creation by up to 10X, but we think we can push it even further!\\n\\nUpload your models to see how AIAD can help you write model documentation.\\n\\nHappy writing, building!\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 11,
            "input_data": "b\"5 Lessons From Building a #GenAI Product for Model Documentation\\nAugust 29, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nManasi Vartak\\n\\nIn July, we launched AI-Assisted Documentation (AIAD) in Verta, a new feature that uses generative AI to help data scientists write high-quality model documentation in minutes rather than hours. We\\xe2\\x80\\x99re already getting some great feedback on this feature (and if you\\xe2\\x80\\x99ve ever felt like model documentation should be less tedious, we\\xe2\\x80\\x99d encourage you to try it out!) \\n\\n \\n\\n\\n\\n \\n\\nIn the spirit of sharing with others who are navigating the new, fast-paced, and sometimes overwhelming world of building with Gen AI, we wanted to reflect on the top lessons we learned from developing this feature.\\n\\nLesson 1: Prototyping is easy; Productizing is hard\\nWe hacked up the first version of AI-Assisted Documentation in a few hours over a weekend. Its initial promise was AWESOME \\xe2\\x80\\x94 give it a bit of input and have it produce beautiful and coherent documentation. However, productizing it took many many weeks and months, a process that included refining the model and prompts, collecting training and validation data, building the right APIs, building the right front-end experience for users to correctly utilize the model, and then making it production-ready so it could handle large amounts of traffic.\\n\\nWe found that the biggest hurdle in productizing a Gen AI application, besides nailing the user experience, is ensuring that the AI model produces consistently high-quality outputs in a variety of input scenarios (more on this in Lesson 2).\\n\\n10% of the work is prototyping something cool, 90% of it is actually making it work each time and predictably. \\n\\nLesson 2. Making results consistent and \\xe2\\x80\\x9cfit-for-purpose\\xe2\\x80\\x9d is hard\\nOur GenAI application assists data scientists in writing model documentation. So \\xe2\\x80\\x9cfit-for-purpose\\xe2\\x80\\x9d in our case means that any text produced by a language model has to be acceptable to a DS, with characteristics like the appropriate tone, word choice, reading comprehension level, and brevity. Depending on the prompts we tried, GPT\\xe2\\x80\\x99s outputs ranged from \\xe2\\x80\\x9ca high-schooler wrote this answer\\xe2\\x80\\x9d (complete with filler words) to this description was \\xe2\\x80\\x9cconstructed by a proficient data scientist.\\xe2\\x80\\x9d\\n\\nUltimately, achieving consistent, high-quality results meant many rounds of prompt engineering iterations, in addition to developing a training dataset of good model documentation examples.\\n\\nLesson 3. Hallucinations instantly break credibility\\nFor our use case, data scientists would answer a series of questions and GPT would expand and rewrite their answers to create a complete set of model documentation. In text rewriting, hallucinations may not seem like such a big deal. How much can the model really veer off course? \\n\\nWe discovered that while, complete fabrications were unusual,  the model would frequently use out-of-context information that instantly breaks credibility. For instance, in the example below, expanding demographics to \\xe2\\x80\\x9cage, education, marital status etc\\xe2\\x80\\x9d may be accurate in some cases \\xe2\\x80\\x94 but in others, using marital status may be prohibited by law, making the expansion unacceptable.\\n\\n \\n\\n\\n\\nWe were able to minimize hallucinations using better prompting as well as training data sets, but with LLMs, it\\xe2\\x80\\x99s not possible to reduce the probability of hallucinations to zero. To further mitigate risk, we chose to have the user review and consent before using any generated text. \\n\\nLesson 4: Validation of results is hard\\nAs noted widely, validation of results from a text generation model like GPT is extremely hard. When you're generating text to be fit-for-purpose, not only does the perplexity score matter \\xe2\\x80\\x94 but the metrics that matter a lot more are things like tone, brevity, word choice, etc. (as discussed in Lesson 1). Many of these assessments today need human review and labeling. Therefore validation \\xe2\\x80\\x94 and handling cases where validators disagree \\xe2\\x80\\x94 is still extremely challenging and subjective.\\n\\nPS: We are working on some very interesting work in the space and would love to bounce ideas with folks who have struggled with validation.\\n\\nLesson 5: UX is (almost) everything\\nUsing generative AI in a workflow changes the nature of the workflow itself. In a typical software product, users can expect machine-generated outputs to always make sense. On the other hand, with generative AI, these outputs can be low-quality at times, so the UX needs to support an iterative, trial-and-error workflow. UX patterns for these kinds of workflows aren\\xe2\\x80\\x99t common (yet). Since users will be learning how to interact with the AI assistance for the first time, we also need many tutorials built into the product that help with discovery and onboarding. \\n\\nWe\\xe2\\x80\\x99d love to hear what you think of AI-Assisted Documentation in Verta. To check it out, go to app.verta.ai and look for the Documentation tab for any model. You can read more about the feature and our goal to reduce the time it takes to write model documentation by over 10x on our blog. \"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 12,
            "input_data": "b\"5 Lessons From Building a #GenAI Product for Model Documentation\\nAugust 29, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nManasi Vartak\\n\\nIn July, we launched AI-Assisted Documentation (AIAD) in Verta, a new feature that uses generative AI to help data scientists write high-quality model documentation in minutes rather than hours. We\\xe2\\x80\\x99re already getting some great feedback on this feature (and if you\\xe2\\x80\\x99ve ever felt like model documentation should be less tedious, we\\xe2\\x80\\x99d encourage you to try it out!) \\n\\n \\n\\n\\n\\n \\n\\nIn the spirit of sharing with others who are navigating the new, fast-paced, and sometimes overwhelming world of building with Gen AI, we wanted to reflect on the top lessons we learned from developing this feature.\\n\\nLesson 1: Prototyping is easy; Productizing is hard\\nWe hacked up the first version of AI-Assisted Documentation in a few hours over a weekend. Its initial promise was AWESOME \\xe2\\x80\\x94 give it a bit of input and have it produce beautiful and coherent documentation. However, productizing it took many many weeks and months, a process that included refining the model and prompts, collecting training and validation data, building the right APIs, building the right front-end experience for users to correctly utilize the model, and then making it production-ready so it could handle large amounts of traffic.\\n\\nWe found that the biggest hurdle in productizing a Gen AI application, besides nailing the user experience, is ensuring that the AI model produces consistently high-quality outputs in a variety of input scenarios (more on this in Lesson 2).\\n\\n10% of the work is prototyping something cool, 90% of it is actually making it work each time and predictably. \\n\\nLesson 2. Making results consistent and \\xe2\\x80\\x9cfit-for-purpose\\xe2\\x80\\x9d is hard\\nOur GenAI application assists data scientists in writing model documentation. So \\xe2\\x80\\x9cfit-for-purpose\\xe2\\x80\\x9d in our case means that any text produced by a language model has to be acceptable to a DS, with characteristics like the appropriate tone, word choice, reading comprehension level, and brevity. Depending on the prompts we tried, GPT\\xe2\\x80\\x99s outputs ranged from \\xe2\\x80\\x9ca high-schooler wrote this answer\\xe2\\x80\\x9d (complete with filler words) to this description was \\xe2\\x80\\x9cconstructed by a proficient data scientist.\\xe2\\x80\\x9d\\n\\nUltimately, achieving consistent, high-quality results meant many rounds of prompt engineering iterations, in addition to developing a training dataset of good model documentation examples.\\n\\nLesson 3. Hallucinations instantly break credibility\\nFor our use case, data scientists would answer a series of questions and GPT would expand and rewrite their answers to create a complete set of model documentation. In text rewriting, hallucinations may not seem like such a big deal. How much can the model really veer off course? \\n\\nWe discovered that while, complete fabrications were unusual,  the model would frequently use out-of-context information that instantly breaks credibility. For instance, in the example below, expanding demographics to \\xe2\\x80\\x9cage, education, marital status etc\\xe2\\x80\\x9d may be accurate in some cases \\xe2\\x80\\x94 but in others, using marital status may be prohibited by law, making the expansion unacceptable.\\n\\n \\n\\n\\n\\nWe were able to minimize hallucinations using better prompting as well as training data sets, but with LLMs, it\\xe2\\x80\\x99s not possible to reduce the probability of hallucinations to zero. To further mitigate risk, we chose to have the user review and consent before using any generated text. \\n\\nLesson 4: Validation of results is hard\\nAs noted widely, validation of results from a text generation model like GPT is extremely hard. When you're generating text to be fit-for-purpose, not only does the perplexity score matter \\xe2\\x80\\x94 but the metrics that matter a lot more are things like tone, brevity, word choice, etc. (as discussed in Lesson 1). Many of these assessments today need human review and labeling. Therefore validation \\xe2\\x80\\x94 and handling cases where validators disagree \\xe2\\x80\\x94 is still extremely challenging and subjective.\\n\\nPS: We are working on some very interesting work in the space and would love to bounce ideas with folks who have struggled with validation.\\n\\nLesson 5: UX is (almost) everything\\nUsing generative AI in a workflow changes the nature of the workflow itself. In a typical software product, users can expect machine-generated outputs to always make sense. On the other hand, with generative AI, these outputs can be low-quality at times, so the UX needs to support an iterative, trial-and-error workflow. UX patterns for these kinds of workflows aren\\xe2\\x80\\x99t common (yet). Since users will be learning how to interact with the AI assistance for the first time, we also need many tutorials built into the product that help with discovery and onboarding. \\n\\nWe\\xe2\\x80\\x99d love to hear what you think of AI-Assisted Documentation in Verta. To check it out, go to app.verta.ai and look for the Documentation tab for any model. You can read more about the feature and our goal to reduce the time it takes to write model documentation by over 10x on our blog. \"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 13,
            "input_data": "b\"3 Documentation Horror Stories and How to Avoid Them\\nAugust 08, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nBaasit Sharief\\n\\nAs data scientists, we have all heard (if not experienced) documentation horror stories - what can go wrong when we don\\xe2\\x80\\x99t take the time to thoroughly document our models. As part of my work on improving documentation processes at my company, Verta, I\\xe2\\x80\\x99ve collected (and anonymized) a \\xe2\\x80\\x9chall of shame\\xe2\\x80\\x9d for stories that highlight solutions for avoiding the pitfalls of poor documentation.\\n\\nHorror Story #1 \\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThe DS team at an online network needed to fix a model used to identify inappropriate content. The model had degraded over time, but when the responsible team looked into it, they realized that they had no documentation, no source code, and no idea how the model was created or what dataset was used to produce it.\\n\\nThe company had to assign a team member to reverse engineer the model that was running in production, then go on a fishing expedition through the data lake to identify which dataset was used to create this model. The team eventually replicated the model to the best of their ability, after which they could work on improving the model. Time lost: Six months.\\n\\nLesson learned: Prioritize documentation. \\nHey, we get it, no one likes documentation. It\\xe2\\x80\\x99s overhead that comes with the job, like meetings. But documentation should be viewed as an integral part of the job, not as something separate. As data scientists, we need to embrace a culture of documentation within the organization, where it is consistently created, updated and maintained throughout the model's lifecycle. \\n\\nHorror Story #2\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nFacing a crisis, a government agency contracted with a private firm for a tool to sift through social media posts to identify threats based on keywords, with a turnaround time of 72 hours. The firm didn't have time to train a new model, but they had an existing model that would work. However, they needed to understand whether they could legally reuse the model and whether it would perform as required. \\n\\nThe data scientist who made the model 14 months prior was still at the company, but they had recorded all their \\xe2\\x80\\x9cdocumentation\\xe2\\x80\\x9d by hand in a notebook that got filed away and forgotten after that project was completed. After a frantic day-long search through old banker\\xe2\\x80\\x99s boxes stored in a garage, eventually the notebook turned up. The firm met the deadline \\xe2\\x80\\x93 but only because the data scientist hadn't left the company and was able to find the long-lost notebook with the critical information. \\n\\nLesson learned: Centralize your documentation. \\nAs a group, data science needs to agree on some one tool or platform as a system of record for documentation. It should be easy to access and search, a place where we can create, maintain, tag and especially share our documentation both within our own group and with other functions in the organization. Opening up access to our documentation to other groups will ensure that we\\xe2\\x80\\x99re preserving the right set of information to meet requirements like regulatory compliance. It also will minimize the disruption of shoulder taps or Slack messages asking about a project that we worked on a year ago.\\n\\nHorror Story #3\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThis is really my own horror story that I\\xe2\\x80\\x99ve seen play out again and again. In general, I find that data scientists have a good understanding of what solid documentation looks like. But, in a sense, that discourages us from providing full documentation of our work, because we are under so much pressure to produce output quickly. Documentation slows us down and, in the short term at least, doesn't seem to provide added value.\\n\\nTo be blunt, documentation doesn't make people happy, and if you make people unhappy enough, they'll leave. So organizations wind up trying to find a middle ground where they are capturing the right level of documentation they need to de-risk the company, but doing it in a way that doesn't make people so unhappy that they leave. Unfortunately, in the absence of clear guidelines, the \\xe2\\x80\\x9cright level of documentation\\xe2\\x80\\x9d often winds up being no documentation at all.\\n\\nLesson learned: Make good documentation easy.\\nWe can make it easier to produce good documentation by agreeing on clear guidelines and standards for what constitutes good documentation. This means capturing information that is essential for our own team but also working with other teams - like IT, legal, governance, and risk management - to ensure we\\xe2\\x80\\x99re capturing the information they need and in an appropriate format. \\n\\nWe need to make sure that the \\xe2\\x80\\x9cright level\\xe2\\x80\\x9d of documentation is not nothing, but also isn\\xe2\\x80\\x99t overkill. Optimally, whatever tool we\\xe2\\x80\\x99re using would have the documentation baked in or, at the least, makes it easy to capture this right set of information. At my company, Verta, we\\xe2\\x80\\x99re even experimenting with using generative AI to create a first draft of documentation that can then be reviewed before publishing to ensure accuracy and completeness.\\n\\nWith a documentation culture, a centralized system of record for documentation, and standardized processes, we can take much of the pain out of documentation, save ourselves time and hassle, and - hopefully - avoid any documentation horror stories of our own. \\n\\nIn the meantime, I\\xe2\\x80\\x99d welcome hearing about your own documentation horror stories or how your organization is using tools like generative AI to prevent documentation nightmares - email me at baasit@verta.ai, or connect with me on LinkedIn at https://www.linkedin.com/in/baasit-sharief/.\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 14,
            "input_data": "b\"3 Documentation Horror Stories and How to Avoid Them\\nAugust 08, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nBaasit Sharief\\n\\nAs data scientists, we have all heard (if not experienced) documentation horror stories - what can go wrong when we don\\xe2\\x80\\x99t take the time to thoroughly document our models. As part of my work on improving documentation processes at my company, Verta, I\\xe2\\x80\\x99ve collected (and anonymized) a \\xe2\\x80\\x9chall of shame\\xe2\\x80\\x9d for stories that highlight solutions for avoiding the pitfalls of poor documentation.\\n\\nHorror Story #1 \\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThe DS team at an online network needed to fix a model used to identify inappropriate content. The model had degraded over time, but when the responsible team looked into it, they realized that they had no documentation, no source code, and no idea how the model was created or what dataset was used to produce it.\\n\\nThe company had to assign a team member to reverse engineer the model that was running in production, then go on a fishing expedition through the data lake to identify which dataset was used to create this model. The team eventually replicated the model to the best of their ability, after which they could work on improving the model. Time lost: Six months.\\n\\nLesson learned: Prioritize documentation. \\nHey, we get it, no one likes documentation. It\\xe2\\x80\\x99s overhead that comes with the job, like meetings. But documentation should be viewed as an integral part of the job, not as something separate. As data scientists, we need to embrace a culture of documentation within the organization, where it is consistently created, updated and maintained throughout the model's lifecycle. \\n\\nHorror Story #2\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nFacing a crisis, a government agency contracted with a private firm for a tool to sift through social media posts to identify threats based on keywords, with a turnaround time of 72 hours. The firm didn't have time to train a new model, but they had an existing model that would work. However, they needed to understand whether they could legally reuse the model and whether it would perform as required. \\n\\nThe data scientist who made the model 14 months prior was still at the company, but they had recorded all their \\xe2\\x80\\x9cdocumentation\\xe2\\x80\\x9d by hand in a notebook that got filed away and forgotten after that project was completed. After a frantic day-long search through old banker\\xe2\\x80\\x99s boxes stored in a garage, eventually the notebook turned up. The firm met the deadline \\xe2\\x80\\x93 but only because the data scientist hadn't left the company and was able to find the long-lost notebook with the critical information. \\n\\nLesson learned: Centralize your documentation. \\nAs a group, data science needs to agree on some one tool or platform as a system of record for documentation. It should be easy to access and search, a place where we can create, maintain, tag and especially share our documentation both within our own group and with other functions in the organization. Opening up access to our documentation to other groups will ensure that we\\xe2\\x80\\x99re preserving the right set of information to meet requirements like regulatory compliance. It also will minimize the disruption of shoulder taps or Slack messages asking about a project that we worked on a year ago.\\n\\nHorror Story #3\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThis is really my own horror story that I\\xe2\\x80\\x99ve seen play out again and again. In general, I find that data scientists have a good understanding of what solid documentation looks like. But, in a sense, that discourages us from providing full documentation of our work, because we are under so much pressure to produce output quickly. Documentation slows us down and, in the short term at least, doesn't seem to provide added value.\\n\\nTo be blunt, documentation doesn't make people happy, and if you make people unhappy enough, they'll leave. So organizations wind up trying to find a middle ground where they are capturing the right level of documentation they need to de-risk the company, but doing it in a way that doesn't make people so unhappy that they leave. Unfortunately, in the absence of clear guidelines, the \\xe2\\x80\\x9cright level of documentation\\xe2\\x80\\x9d often winds up being no documentation at all.\\n\\nLesson learned: Make good documentation easy.\\nWe can make it easier to produce good documentation by agreeing on clear guidelines and standards for what constitutes good documentation. This means capturing information that is essential for our own team but also working with other teams - like IT, legal, governance, and risk management - to ensure we\\xe2\\x80\\x99re capturing the information they need and in an appropriate format. \\n\\nWe need to make sure that the \\xe2\\x80\\x9cright level\\xe2\\x80\\x9d of documentation is not nothing, but also isn\\xe2\\x80\\x99t overkill. Optimally, whatever tool we\\xe2\\x80\\x99re using would have the documentation baked in or, at the least, makes it easy to capture this right set of information. At my company, Verta, we\\xe2\\x80\\x99re even experimenting with using generative AI to create a first draft of documentation that can then be reviewed before publishing to ensure accuracy and completeness.\\n\\nWith a documentation culture, a centralized system of record for documentation, and standardized processes, we can take much of the pain out of documentation, save ourselves time and hassle, and - hopefully - avoid any documentation horror stories of our own. \\n\\nIn the meantime, I\\xe2\\x80\\x99d welcome hearing about your own documentation horror stories or how your organization is using tools like generative AI to prevent documentation nightmares - email me at baasit@verta.ai, or connect with me on LinkedIn at https://www.linkedin.com/in/baasit-sharief/.\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 15,
            "input_data": "b\"3 Documentation Horror Stories and How to Avoid Them\\nAugust 08, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nBaasit Sharief\\n\\nAs data scientists, we have all heard (if not experienced) documentation horror stories - what can go wrong when we don\\xe2\\x80\\x99t take the time to thoroughly document our models. As part of my work on improving documentation processes at my company, Verta, I\\xe2\\x80\\x99ve collected (and anonymized) a \\xe2\\x80\\x9chall of shame\\xe2\\x80\\x9d for stories that highlight solutions for avoiding the pitfalls of poor documentation.\\n\\nHorror Story #1 \\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThe DS team at an online network needed to fix a model used to identify inappropriate content. The model had degraded over time, but when the responsible team looked into it, they realized that they had no documentation, no source code, and no idea how the model was created or what dataset was used to produce it.\\n\\nThe company had to assign a team member to reverse engineer the model that was running in production, then go on a fishing expedition through the data lake to identify which dataset was used to create this model. The team eventually replicated the model to the best of their ability, after which they could work on improving the model. Time lost: Six months.\\n\\nLesson learned: Prioritize documentation. \\nHey, we get it, no one likes documentation. It\\xe2\\x80\\x99s overhead that comes with the job, like meetings. But documentation should be viewed as an integral part of the job, not as something separate. As data scientists, we need to embrace a culture of documentation within the organization, where it is consistently created, updated and maintained throughout the model's lifecycle. \\n\\nHorror Story #2\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nFacing a crisis, a government agency contracted with a private firm for a tool to sift through social media posts to identify threats based on keywords, with a turnaround time of 72 hours. The firm didn't have time to train a new model, but they had an existing model that would work. However, they needed to understand whether they could legally reuse the model and whether it would perform as required. \\n\\nThe data scientist who made the model 14 months prior was still at the company, but they had recorded all their \\xe2\\x80\\x9cdocumentation\\xe2\\x80\\x9d by hand in a notebook that got filed away and forgotten after that project was completed. After a frantic day-long search through old banker\\xe2\\x80\\x99s boxes stored in a garage, eventually the notebook turned up. The firm met the deadline \\xe2\\x80\\x93 but only because the data scientist hadn't left the company and was able to find the long-lost notebook with the critical information. \\n\\nLesson learned: Centralize your documentation. \\nAs a group, data science needs to agree on some one tool or platform as a system of record for documentation. It should be easy to access and search, a place where we can create, maintain, tag and especially share our documentation both within our own group and with other functions in the organization. Opening up access to our documentation to other groups will ensure that we\\xe2\\x80\\x99re preserving the right set of information to meet requirements like regulatory compliance. It also will minimize the disruption of shoulder taps or Slack messages asking about a project that we worked on a year ago.\\n\\nHorror Story #3\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThis is really my own horror story that I\\xe2\\x80\\x99ve seen play out again and again. In general, I find that data scientists have a good understanding of what solid documentation looks like. But, in a sense, that discourages us from providing full documentation of our work, because we are under so much pressure to produce output quickly. Documentation slows us down and, in the short term at least, doesn't seem to provide added value.\\n\\nTo be blunt, documentation doesn't make people happy, and if you make people unhappy enough, they'll leave. So organizations wind up trying to find a middle ground where they are capturing the right level of documentation they need to de-risk the company, but doing it in a way that doesn't make people so unhappy that they leave. Unfortunately, in the absence of clear guidelines, the \\xe2\\x80\\x9cright level of documentation\\xe2\\x80\\x9d often winds up being no documentation at all.\\n\\nLesson learned: Make good documentation easy.\\nWe can make it easier to produce good documentation by agreeing on clear guidelines and standards for what constitutes good documentation. This means capturing information that is essential for our own team but also working with other teams - like IT, legal, governance, and risk management - to ensure we\\xe2\\x80\\x99re capturing the information they need and in an appropriate format. \\n\\nWe need to make sure that the \\xe2\\x80\\x9cright level\\xe2\\x80\\x9d of documentation is not nothing, but also isn\\xe2\\x80\\x99t overkill. Optimally, whatever tool we\\xe2\\x80\\x99re using would have the documentation baked in or, at the least, makes it easy to capture this right set of information. At my company, Verta, we\\xe2\\x80\\x99re even experimenting with using generative AI to create a first draft of documentation that can then be reviewed before publishing to ensure accuracy and completeness.\\n\\nWith a documentation culture, a centralized system of record for documentation, and standardized processes, we can take much of the pain out of documentation, save ourselves time and hassle, and - hopefully - avoid any documentation horror stories of our own. \\n\\nIn the meantime, I\\xe2\\x80\\x99d welcome hearing about your own documentation horror stories or how your organization is using tools like generative AI to prevent documentation nightmares - email me at baasit@verta.ai, or connect with me on LinkedIn at https://www.linkedin.com/in/baasit-sharief/.\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 16,
            "input_data": "b\"3 Documentation Horror Stories and How to Avoid Them\\nAugust 08, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nBaasit Sharief\\n\\nAs data scientists, we have all heard (if not experienced) documentation horror stories - what can go wrong when we don\\xe2\\x80\\x99t take the time to thoroughly document our models. As part of my work on improving documentation processes at my company, Verta, I\\xe2\\x80\\x99ve collected (and anonymized) a \\xe2\\x80\\x9chall of shame\\xe2\\x80\\x9d for stories that highlight solutions for avoiding the pitfalls of poor documentation.\\n\\nHorror Story #1 \\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThe DS team at an online network needed to fix a model used to identify inappropriate content. The model had degraded over time, but when the responsible team looked into it, they realized that they had no documentation, no source code, and no idea how the model was created or what dataset was used to produce it.\\n\\nThe company had to assign a team member to reverse engineer the model that was running in production, then go on a fishing expedition through the data lake to identify which dataset was used to create this model. The team eventually replicated the model to the best of their ability, after which they could work on improving the model. Time lost: Six months.\\n\\nLesson learned: Prioritize documentation. \\nHey, we get it, no one likes documentation. It\\xe2\\x80\\x99s overhead that comes with the job, like meetings. But documentation should be viewed as an integral part of the job, not as something separate. As data scientists, we need to embrace a culture of documentation within the organization, where it is consistently created, updated and maintained throughout the model's lifecycle. \\n\\nHorror Story #2\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nFacing a crisis, a government agency contracted with a private firm for a tool to sift through social media posts to identify threats based on keywords, with a turnaround time of 72 hours. The firm didn't have time to train a new model, but they had an existing model that would work. However, they needed to understand whether they could legally reuse the model and whether it would perform as required. \\n\\nThe data scientist who made the model 14 months prior was still at the company, but they had recorded all their \\xe2\\x80\\x9cdocumentation\\xe2\\x80\\x9d by hand in a notebook that got filed away and forgotten after that project was completed. After a frantic day-long search through old banker\\xe2\\x80\\x99s boxes stored in a garage, eventually the notebook turned up. The firm met the deadline \\xe2\\x80\\x93 but only because the data scientist hadn't left the company and was able to find the long-lost notebook with the critical information. \\n\\nLesson learned: Centralize your documentation. \\nAs a group, data science needs to agree on some one tool or platform as a system of record for documentation. It should be easy to access and search, a place where we can create, maintain, tag and especially share our documentation both within our own group and with other functions in the organization. Opening up access to our documentation to other groups will ensure that we\\xe2\\x80\\x99re preserving the right set of information to meet requirements like regulatory compliance. It also will minimize the disruption of shoulder taps or Slack messages asking about a project that we worked on a year ago.\\n\\nHorror Story #3\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThis is really my own horror story that I\\xe2\\x80\\x99ve seen play out again and again. In general, I find that data scientists have a good understanding of what solid documentation looks like. But, in a sense, that discourages us from providing full documentation of our work, because we are under so much pressure to produce output quickly. Documentation slows us down and, in the short term at least, doesn't seem to provide added value.\\n\\nTo be blunt, documentation doesn't make people happy, and if you make people unhappy enough, they'll leave. So organizations wind up trying to find a middle ground where they are capturing the right level of documentation they need to de-risk the company, but doing it in a way that doesn't make people so unhappy that they leave. Unfortunately, in the absence of clear guidelines, the \\xe2\\x80\\x9cright level of documentation\\xe2\\x80\\x9d often winds up being no documentation at all.\\n\\nLesson learned: Make good documentation easy.\\nWe can make it easier to produce good documentation by agreeing on clear guidelines and standards for what constitutes good documentation. This means capturing information that is essential for our own team but also working with other teams - like IT, legal, governance, and risk management - to ensure we\\xe2\\x80\\x99re capturing the information they need and in an appropriate format. \\n\\nWe need to make sure that the \\xe2\\x80\\x9cright level\\xe2\\x80\\x9d of documentation is not nothing, but also isn\\xe2\\x80\\x99t overkill. Optimally, whatever tool we\\xe2\\x80\\x99re using would have the documentation baked in or, at the least, makes it easy to capture this right set of information. At my company, Verta, we\\xe2\\x80\\x99re even experimenting with using generative AI to create a first draft of documentation that can then be reviewed before publishing to ensure accuracy and completeness.\\n\\nWith a documentation culture, a centralized system of record for documentation, and standardized processes, we can take much of the pain out of documentation, save ourselves time and hassle, and - hopefully - avoid any documentation horror stories of our own. \\n\\nIn the meantime, I\\xe2\\x80\\x99d welcome hearing about your own documentation horror stories or how your organization is using tools like generative AI to prevent documentation nightmares - email me at baasit@verta.ai, or connect with me on LinkedIn at https://www.linkedin.com/in/baasit-sharief/.\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 17,
            "input_data": "b\"3 Documentation Horror Stories and How to Avoid Them\\nAugust 08, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nBaasit Sharief\\n\\nAs data scientists, we have all heard (if not experienced) documentation horror stories - what can go wrong when we don\\xe2\\x80\\x99t take the time to thoroughly document our models. As part of my work on improving documentation processes at my company, Verta, I\\xe2\\x80\\x99ve collected (and anonymized) a \\xe2\\x80\\x9chall of shame\\xe2\\x80\\x9d for stories that highlight solutions for avoiding the pitfalls of poor documentation.\\n\\nHorror Story #1 \\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThe DS team at an online network needed to fix a model used to identify inappropriate content. The model had degraded over time, but when the responsible team looked into it, they realized that they had no documentation, no source code, and no idea how the model was created or what dataset was used to produce it.\\n\\nThe company had to assign a team member to reverse engineer the model that was running in production, then go on a fishing expedition through the data lake to identify which dataset was used to create this model. The team eventually replicated the model to the best of their ability, after which they could work on improving the model. Time lost: Six months.\\n\\nLesson learned: Prioritize documentation. \\nHey, we get it, no one likes documentation. It\\xe2\\x80\\x99s overhead that comes with the job, like meetings. But documentation should be viewed as an integral part of the job, not as something separate. As data scientists, we need to embrace a culture of documentation within the organization, where it is consistently created, updated and maintained throughout the model's lifecycle. \\n\\nHorror Story #2\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nFacing a crisis, a government agency contracted with a private firm for a tool to sift through social media posts to identify threats based on keywords, with a turnaround time of 72 hours. The firm didn't have time to train a new model, but they had an existing model that would work. However, they needed to understand whether they could legally reuse the model and whether it would perform as required. \\n\\nThe data scientist who made the model 14 months prior was still at the company, but they had recorded all their \\xe2\\x80\\x9cdocumentation\\xe2\\x80\\x9d by hand in a notebook that got filed away and forgotten after that project was completed. After a frantic day-long search through old banker\\xe2\\x80\\x99s boxes stored in a garage, eventually the notebook turned up. The firm met the deadline \\xe2\\x80\\x93 but only because the data scientist hadn't left the company and was able to find the long-lost notebook with the critical information. \\n\\nLesson learned: Centralize your documentation. \\nAs a group, data science needs to agree on some one tool or platform as a system of record for documentation. It should be easy to access and search, a place where we can create, maintain, tag and especially share our documentation both within our own group and with other functions in the organization. Opening up access to our documentation to other groups will ensure that we\\xe2\\x80\\x99re preserving the right set of information to meet requirements like regulatory compliance. It also will minimize the disruption of shoulder taps or Slack messages asking about a project that we worked on a year ago.\\n\\nHorror Story #3\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThis is really my own horror story that I\\xe2\\x80\\x99ve seen play out again and again. In general, I find that data scientists have a good understanding of what solid documentation looks like. But, in a sense, that discourages us from providing full documentation of our work, because we are under so much pressure to produce output quickly. Documentation slows us down and, in the short term at least, doesn't seem to provide added value.\\n\\nTo be blunt, documentation doesn't make people happy, and if you make people unhappy enough, they'll leave. So organizations wind up trying to find a middle ground where they are capturing the right level of documentation they need to de-risk the company, but doing it in a way that doesn't make people so unhappy that they leave. Unfortunately, in the absence of clear guidelines, the \\xe2\\x80\\x9cright level of documentation\\xe2\\x80\\x9d often winds up being no documentation at all.\\n\\nLesson learned: Make good documentation easy.\\nWe can make it easier to produce good documentation by agreeing on clear guidelines and standards for what constitutes good documentation. This means capturing information that is essential for our own team but also working with other teams - like IT, legal, governance, and risk management - to ensure we\\xe2\\x80\\x99re capturing the information they need and in an appropriate format. \\n\\nWe need to make sure that the \\xe2\\x80\\x9cright level\\xe2\\x80\\x9d of documentation is not nothing, but also isn\\xe2\\x80\\x99t overkill. Optimally, whatever tool we\\xe2\\x80\\x99re using would have the documentation baked in or, at the least, makes it easy to capture this right set of information. At my company, Verta, we\\xe2\\x80\\x99re even experimenting with using generative AI to create a first draft of documentation that can then be reviewed before publishing to ensure accuracy and completeness.\\n\\nWith a documentation culture, a centralized system of record for documentation, and standardized processes, we can take much of the pain out of documentation, save ourselves time and hassle, and - hopefully - avoid any documentation horror stories of our own. \\n\\nIn the meantime, I\\xe2\\x80\\x99d welcome hearing about your own documentation horror stories or how your organization is using tools like generative AI to prevent documentation nightmares - email me at baasit@verta.ai, or connect with me on LinkedIn at https://www.linkedin.com/in/baasit-sharief/.\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 18,
            "input_data": "b\"3 Documentation Horror Stories and How to Avoid Them\\nAugust 08, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nBaasit Sharief\\n\\nAs data scientists, we have all heard (if not experienced) documentation horror stories - what can go wrong when we don\\xe2\\x80\\x99t take the time to thoroughly document our models. As part of my work on improving documentation processes at my company, Verta, I\\xe2\\x80\\x99ve collected (and anonymized) a \\xe2\\x80\\x9chall of shame\\xe2\\x80\\x9d for stories that highlight solutions for avoiding the pitfalls of poor documentation.\\n\\nHorror Story #1 \\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThe DS team at an online network needed to fix a model used to identify inappropriate content. The model had degraded over time, but when the responsible team looked into it, they realized that they had no documentation, no source code, and no idea how the model was created or what dataset was used to produce it.\\n\\nThe company had to assign a team member to reverse engineer the model that was running in production, then go on a fishing expedition through the data lake to identify which dataset was used to create this model. The team eventually replicated the model to the best of their ability, after which they could work on improving the model. Time lost: Six months.\\n\\nLesson learned: Prioritize documentation. \\nHey, we get it, no one likes documentation. It\\xe2\\x80\\x99s overhead that comes with the job, like meetings. But documentation should be viewed as an integral part of the job, not as something separate. As data scientists, we need to embrace a culture of documentation within the organization, where it is consistently created, updated and maintained throughout the model's lifecycle. \\n\\nHorror Story #2\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nFacing a crisis, a government agency contracted with a private firm for a tool to sift through social media posts to identify threats based on keywords, with a turnaround time of 72 hours. The firm didn't have time to train a new model, but they had an existing model that would work. However, they needed to understand whether they could legally reuse the model and whether it would perform as required. \\n\\nThe data scientist who made the model 14 months prior was still at the company, but they had recorded all their \\xe2\\x80\\x9cdocumentation\\xe2\\x80\\x9d by hand in a notebook that got filed away and forgotten after that project was completed. After a frantic day-long search through old banker\\xe2\\x80\\x99s boxes stored in a garage, eventually the notebook turned up. The firm met the deadline \\xe2\\x80\\x93 but only because the data scientist hadn't left the company and was able to find the long-lost notebook with the critical information. \\n\\nLesson learned: Centralize your documentation. \\nAs a group, data science needs to agree on some one tool or platform as a system of record for documentation. It should be easy to access and search, a place where we can create, maintain, tag and especially share our documentation both within our own group and with other functions in the organization. Opening up access to our documentation to other groups will ensure that we\\xe2\\x80\\x99re preserving the right set of information to meet requirements like regulatory compliance. It also will minimize the disruption of shoulder taps or Slack messages asking about a project that we worked on a year ago.\\n\\nHorror Story #3\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThis is really my own horror story that I\\xe2\\x80\\x99ve seen play out again and again. In general, I find that data scientists have a good understanding of what solid documentation looks like. But, in a sense, that discourages us from providing full documentation of our work, because we are under so much pressure to produce output quickly. Documentation slows us down and, in the short term at least, doesn't seem to provide added value.\\n\\nTo be blunt, documentation doesn't make people happy, and if you make people unhappy enough, they'll leave. So organizations wind up trying to find a middle ground where they are capturing the right level of documentation they need to de-risk the company, but doing it in a way that doesn't make people so unhappy that they leave. Unfortunately, in the absence of clear guidelines, the \\xe2\\x80\\x9cright level of documentation\\xe2\\x80\\x9d often winds up being no documentation at all.\\n\\nLesson learned: Make good documentation easy.\\nWe can make it easier to produce good documentation by agreeing on clear guidelines and standards for what constitutes good documentation. This means capturing information that is essential for our own team but also working with other teams - like IT, legal, governance, and risk management - to ensure we\\xe2\\x80\\x99re capturing the information they need and in an appropriate format. \\n\\nWe need to make sure that the \\xe2\\x80\\x9cright level\\xe2\\x80\\x9d of documentation is not nothing, but also isn\\xe2\\x80\\x99t overkill. Optimally, whatever tool we\\xe2\\x80\\x99re using would have the documentation baked in or, at the least, makes it easy to capture this right set of information. At my company, Verta, we\\xe2\\x80\\x99re even experimenting with using generative AI to create a first draft of documentation that can then be reviewed before publishing to ensure accuracy and completeness.\\n\\nWith a documentation culture, a centralized system of record for documentation, and standardized processes, we can take much of the pain out of documentation, save ourselves time and hassle, and - hopefully - avoid any documentation horror stories of our own. \\n\\nIn the meantime, I\\xe2\\x80\\x99d welcome hearing about your own documentation horror stories or how your organization is using tools like generative AI to prevent documentation nightmares - email me at baasit@verta.ai, or connect with me on LinkedIn at https://www.linkedin.com/in/baasit-sharief/.\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 19,
            "input_data": "b\"3 Documentation Horror Stories and How to Avoid Them\\nAugust 08, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nBaasit Sharief\\n\\nAs data scientists, we have all heard (if not experienced) documentation horror stories - what can go wrong when we don\\xe2\\x80\\x99t take the time to thoroughly document our models. As part of my work on improving documentation processes at my company, Verta, I\\xe2\\x80\\x99ve collected (and anonymized) a \\xe2\\x80\\x9chall of shame\\xe2\\x80\\x9d for stories that highlight solutions for avoiding the pitfalls of poor documentation.\\n\\nHorror Story #1 \\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThe DS team at an online network needed to fix a model used to identify inappropriate content. The model had degraded over time, but when the responsible team looked into it, they realized that they had no documentation, no source code, and no idea how the model was created or what dataset was used to produce it.\\n\\nThe company had to assign a team member to reverse engineer the model that was running in production, then go on a fishing expedition through the data lake to identify which dataset was used to create this model. The team eventually replicated the model to the best of their ability, after which they could work on improving the model. Time lost: Six months.\\n\\nLesson learned: Prioritize documentation. \\nHey, we get it, no one likes documentation. It\\xe2\\x80\\x99s overhead that comes with the job, like meetings. But documentation should be viewed as an integral part of the job, not as something separate. As data scientists, we need to embrace a culture of documentation within the organization, where it is consistently created, updated and maintained throughout the model's lifecycle. \\n\\nHorror Story #2\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nFacing a crisis, a government agency contracted with a private firm for a tool to sift through social media posts to identify threats based on keywords, with a turnaround time of 72 hours. The firm didn't have time to train a new model, but they had an existing model that would work. However, they needed to understand whether they could legally reuse the model and whether it would perform as required. \\n\\nThe data scientist who made the model 14 months prior was still at the company, but they had recorded all their \\xe2\\x80\\x9cdocumentation\\xe2\\x80\\x9d by hand in a notebook that got filed away and forgotten after that project was completed. After a frantic day-long search through old banker\\xe2\\x80\\x99s boxes stored in a garage, eventually the notebook turned up. The firm met the deadline \\xe2\\x80\\x93 but only because the data scientist hadn't left the company and was able to find the long-lost notebook with the critical information. \\n\\nLesson learned: Centralize your documentation. \\nAs a group, data science needs to agree on some one tool or platform as a system of record for documentation. It should be easy to access and search, a place where we can create, maintain, tag and especially share our documentation both within our own group and with other functions in the organization. Opening up access to our documentation to other groups will ensure that we\\xe2\\x80\\x99re preserving the right set of information to meet requirements like regulatory compliance. It also will minimize the disruption of shoulder taps or Slack messages asking about a project that we worked on a year ago.\\n\\nHorror Story #3\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThis is really my own horror story that I\\xe2\\x80\\x99ve seen play out again and again. In general, I find that data scientists have a good understanding of what solid documentation looks like. But, in a sense, that discourages us from providing full documentation of our work, because we are under so much pressure to produce output quickly. Documentation slows us down and, in the short term at least, doesn't seem to provide added value.\\n\\nTo be blunt, documentation doesn't make people happy, and if you make people unhappy enough, they'll leave. So organizations wind up trying to find a middle ground where they are capturing the right level of documentation they need to de-risk the company, but doing it in a way that doesn't make people so unhappy that they leave. Unfortunately, in the absence of clear guidelines, the \\xe2\\x80\\x9cright level of documentation\\xe2\\x80\\x9d often winds up being no documentation at all.\\n\\nLesson learned: Make good documentation easy.\\nWe can make it easier to produce good documentation by agreeing on clear guidelines and standards for what constitutes good documentation. This means capturing information that is essential for our own team but also working with other teams - like IT, legal, governance, and risk management - to ensure we\\xe2\\x80\\x99re capturing the information they need and in an appropriate format. \\n\\nWe need to make sure that the \\xe2\\x80\\x9cright level\\xe2\\x80\\x9d of documentation is not nothing, but also isn\\xe2\\x80\\x99t overkill. Optimally, whatever tool we\\xe2\\x80\\x99re using would have the documentation baked in or, at the least, makes it easy to capture this right set of information. At my company, Verta, we\\xe2\\x80\\x99re even experimenting with using generative AI to create a first draft of documentation that can then be reviewed before publishing to ensure accuracy and completeness.\\n\\nWith a documentation culture, a centralized system of record for documentation, and standardized processes, we can take much of the pain out of documentation, save ourselves time and hassle, and - hopefully - avoid any documentation horror stories of our own. \\n\\nIn the meantime, I\\xe2\\x80\\x99d welcome hearing about your own documentation horror stories or how your organization is using tools like generative AI to prevent documentation nightmares - email me at baasit@verta.ai, or connect with me on LinkedIn at https://www.linkedin.com/in/baasit-sharief/.\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 20,
            "input_data": "b\"3 Documentation Horror Stories and How to Avoid Them\\nAugust 08, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nBaasit Sharief\\n\\nAs data scientists, we have all heard (if not experienced) documentation horror stories - what can go wrong when we don\\xe2\\x80\\x99t take the time to thoroughly document our models. As part of my work on improving documentation processes at my company, Verta, I\\xe2\\x80\\x99ve collected (and anonymized) a \\xe2\\x80\\x9chall of shame\\xe2\\x80\\x9d for stories that highlight solutions for avoiding the pitfalls of poor documentation.\\n\\nHorror Story #1 \\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThe DS team at an online network needed to fix a model used to identify inappropriate content. The model had degraded over time, but when the responsible team looked into it, they realized that they had no documentation, no source code, and no idea how the model was created or what dataset was used to produce it.\\n\\nThe company had to assign a team member to reverse engineer the model that was running in production, then go on a fishing expedition through the data lake to identify which dataset was used to create this model. The team eventually replicated the model to the best of their ability, after which they could work on improving the model. Time lost: Six months.\\n\\nLesson learned: Prioritize documentation. \\nHey, we get it, no one likes documentation. It\\xe2\\x80\\x99s overhead that comes with the job, like meetings. But documentation should be viewed as an integral part of the job, not as something separate. As data scientists, we need to embrace a culture of documentation within the organization, where it is consistently created, updated and maintained throughout the model's lifecycle. \\n\\nHorror Story #2\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nFacing a crisis, a government agency contracted with a private firm for a tool to sift through social media posts to identify threats based on keywords, with a turnaround time of 72 hours. The firm didn't have time to train a new model, but they had an existing model that would work. However, they needed to understand whether they could legally reuse the model and whether it would perform as required. \\n\\nThe data scientist who made the model 14 months prior was still at the company, but they had recorded all their \\xe2\\x80\\x9cdocumentation\\xe2\\x80\\x9d by hand in a notebook that got filed away and forgotten after that project was completed. After a frantic day-long search through old banker\\xe2\\x80\\x99s boxes stored in a garage, eventually the notebook turned up. The firm met the deadline \\xe2\\x80\\x93 but only because the data scientist hadn't left the company and was able to find the long-lost notebook with the critical information. \\n\\nLesson learned: Centralize your documentation. \\nAs a group, data science needs to agree on some one tool or platform as a system of record for documentation. It should be easy to access and search, a place where we can create, maintain, tag and especially share our documentation both within our own group and with other functions in the organization. Opening up access to our documentation to other groups will ensure that we\\xe2\\x80\\x99re preserving the right set of information to meet requirements like regulatory compliance. It also will minimize the disruption of shoulder taps or Slack messages asking about a project that we worked on a year ago.\\n\\nHorror Story #3\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThis is really my own horror story that I\\xe2\\x80\\x99ve seen play out again and again. In general, I find that data scientists have a good understanding of what solid documentation looks like. But, in a sense, that discourages us from providing full documentation of our work, because we are under so much pressure to produce output quickly. Documentation slows us down and, in the short term at least, doesn't seem to provide added value.\\n\\nTo be blunt, documentation doesn't make people happy, and if you make people unhappy enough, they'll leave. So organizations wind up trying to find a middle ground where they are capturing the right level of documentation they need to de-risk the company, but doing it in a way that doesn't make people so unhappy that they leave. Unfortunately, in the absence of clear guidelines, the \\xe2\\x80\\x9cright level of documentation\\xe2\\x80\\x9d often winds up being no documentation at all.\\n\\nLesson learned: Make good documentation easy.\\nWe can make it easier to produce good documentation by agreeing on clear guidelines and standards for what constitutes good documentation. This means capturing information that is essential for our own team but also working with other teams - like IT, legal, governance, and risk management - to ensure we\\xe2\\x80\\x99re capturing the information they need and in an appropriate format. \\n\\nWe need to make sure that the \\xe2\\x80\\x9cright level\\xe2\\x80\\x9d of documentation is not nothing, but also isn\\xe2\\x80\\x99t overkill. Optimally, whatever tool we\\xe2\\x80\\x99re using would have the documentation baked in or, at the least, makes it easy to capture this right set of information. At my company, Verta, we\\xe2\\x80\\x99re even experimenting with using generative AI to create a first draft of documentation that can then be reviewed before publishing to ensure accuracy and completeness.\\n\\nWith a documentation culture, a centralized system of record for documentation, and standardized processes, we can take much of the pain out of documentation, save ourselves time and hassle, and - hopefully - avoid any documentation horror stories of our own. \\n\\nIn the meantime, I\\xe2\\x80\\x99d welcome hearing about your own documentation horror stories or how your organization is using tools like generative AI to prevent documentation nightmares - email me at baasit@verta.ai, or connect with me on LinkedIn at https://www.linkedin.com/in/baasit-sharief/.\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        },
        {
            "id": 21,
            "input_data": "b\"3 Documentation Horror Stories and How to Avoid Them\\nAugust 08, 2023\\n\\n \\xe2\\x80\\xa2 \\n\\nBaasit Sharief\\n\\nAs data scientists, we have all heard (if not experienced) documentation horror stories - what can go wrong when we don\\xe2\\x80\\x99t take the time to thoroughly document our models. As part of my work on improving documentation processes at my company, Verta, I\\xe2\\x80\\x99ve collected (and anonymized) a \\xe2\\x80\\x9chall of shame\\xe2\\x80\\x9d for stories that highlight solutions for avoiding the pitfalls of poor documentation.\\n\\nHorror Story #1 \\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThe DS team at an online network needed to fix a model used to identify inappropriate content. The model had degraded over time, but when the responsible team looked into it, they realized that they had no documentation, no source code, and no idea how the model was created or what dataset was used to produce it.\\n\\nThe company had to assign a team member to reverse engineer the model that was running in production, then go on a fishing expedition through the data lake to identify which dataset was used to create this model. The team eventually replicated the model to the best of their ability, after which they could work on improving the model. Time lost: Six months.\\n\\nLesson learned: Prioritize documentation. \\nHey, we get it, no one likes documentation. It\\xe2\\x80\\x99s overhead that comes with the job, like meetings. But documentation should be viewed as an integral part of the job, not as something separate. As data scientists, we need to embrace a culture of documentation within the organization, where it is consistently created, updated and maintained throughout the model's lifecycle. \\n\\nHorror Story #2\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nFacing a crisis, a government agency contracted with a private firm for a tool to sift through social media posts to identify threats based on keywords, with a turnaround time of 72 hours. The firm didn't have time to train a new model, but they had an existing model that would work. However, they needed to understand whether they could legally reuse the model and whether it would perform as required. \\n\\nThe data scientist who made the model 14 months prior was still at the company, but they had recorded all their \\xe2\\x80\\x9cdocumentation\\xe2\\x80\\x9d by hand in a notebook that got filed away and forgotten after that project was completed. After a frantic day-long search through old banker\\xe2\\x80\\x99s boxes stored in a garage, eventually the notebook turned up. The firm met the deadline \\xe2\\x80\\x93 but only because the data scientist hadn't left the company and was able to find the long-lost notebook with the critical information. \\n\\nLesson learned: Centralize your documentation. \\nAs a group, data science needs to agree on some one tool or platform as a system of record for documentation. It should be easy to access and search, a place where we can create, maintain, tag and especially share our documentation both within our own group and with other functions in the organization. Opening up access to our documentation to other groups will ensure that we\\xe2\\x80\\x99re preserving the right set of information to meet requirements like regulatory compliance. It also will minimize the disruption of shoulder taps or Slack messages asking about a project that we worked on a year ago.\\n\\nHorror Story #3\\n\\n\\nImage via Dataedo under Creative Commons Attribution-NoDerivs 3.0 License\\n\\nThis is really my own horror story that I\\xe2\\x80\\x99ve seen play out again and again. In general, I find that data scientists have a good understanding of what solid documentation looks like. But, in a sense, that discourages us from providing full documentation of our work, because we are under so much pressure to produce output quickly. Documentation slows us down and, in the short term at least, doesn't seem to provide added value.\\n\\nTo be blunt, documentation doesn't make people happy, and if you make people unhappy enough, they'll leave. So organizations wind up trying to find a middle ground where they are capturing the right level of documentation they need to de-risk the company, but doing it in a way that doesn't make people so unhappy that they leave. Unfortunately, in the absence of clear guidelines, the \\xe2\\x80\\x9cright level of documentation\\xe2\\x80\\x9d often winds up being no documentation at all.\\n\\nLesson learned: Make good documentation easy.\\nWe can make it easier to produce good documentation by agreeing on clear guidelines and standards for what constitutes good documentation. This means capturing information that is essential for our own team but also working with other teams - like IT, legal, governance, and risk management - to ensure we\\xe2\\x80\\x99re capturing the information they need and in an appropriate format. \\n\\nWe need to make sure that the \\xe2\\x80\\x9cright level\\xe2\\x80\\x9d of documentation is not nothing, but also isn\\xe2\\x80\\x99t overkill. Optimally, whatever tool we\\xe2\\x80\\x99re using would have the documentation baked in or, at the least, makes it easy to capture this right set of information. At my company, Verta, we\\xe2\\x80\\x99re even experimenting with using generative AI to create a first draft of documentation that can then be reviewed before publishing to ensure accuracy and completeness.\\n\\nWith a documentation culture, a centralized system of record for documentation, and standardized processes, we can take much of the pain out of documentation, save ourselves time and hassle, and - hopefully - avoid any documentation horror stories of our own. \\n\\nIn the meantime, I\\xe2\\x80\\x99d welcome hearing about your own documentation horror stories or how your organization is using tools like generative AI to prevent documentation nightmares - email me at baasit@verta.ai, or connect with me on LinkedIn at https://www.linkedin.com/in/baasit-sharief/.\\n\"",
            "ground_truth": "",
            "type": "text",
            "metadata": "{}"
        }
    ]
}